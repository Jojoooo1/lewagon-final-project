{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inBFwoQZJJZF"
      },
      "source": [
        "#### Your objective is to classify fMRI brain images taken while listening to music in five different genres: label 0=Ambient Music, 1=Country Music, 2=Heavy Metal, 3=Rock 'n Roll, 4=Classical Symphonic. The data consists of train_data.csv, train_labels.csv, and test_data.csv, for a one-person subset of a larger 20-subject study, linked above.\n",
        "\n",
        "#### The training data (train_data.csv) consist of 160 event-related brain images (trials), corresponding to twenty 6-second music clips, four clips in each of the five genres, repeated in-order eight times (runs). The labels (train_labels.csv) correspond to the correct musical genres, listed above, for each of the 160 trials.\n",
        "\n",
        "#### There are 22036 features in each brain image, corresponding to blood-oxygenation levels at each 2mm-cubed 3D location within a section of the auditory cortex. In human brain imaging, there are often many more features (brain sites) than samples (trials), thus making the task a relatively challenging multiway classification problem.\n",
        "\n",
        "#### The testing data (test_data.csv) consists of 40 event-related brain images corresponding to novel 6-second music clips in the five genres. The test data is in randomized order with no labels. You must predict, using only the given brain images, the correct genre labels (0-4) for the 40 test trials.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25QjbIJtflqc"
      },
      "source": [
        "# Final Project\n",
        "\n",
        "# \"Classifying The Brain on Music\"\n",
        "\n",
        "Michael Casey, https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2017.01179/full\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBkfTOxuWxUY"
      },
      "source": [
        "## **1. Multi-Class Genre Classifier** [[12 points]](https://)\n",
        "\n",
        "#### Build a multi-class classifier for the 5 music genres. Your goal is to train a model to classify brain images into corresponding genre categories. You are free to choose any machine learning models from the class.\n",
        "\n",
        "#### **1-1. Hyper-parameter Search.** [[4 points]](https://) Demonstrate your hyperparameter search process using cross-validation. Provide details for at least one hyperparameter with 10 different possible values.\n",
        "\n",
        "#### **1-2. Model Training and Testing.** [[4 points]](https://) Following the hyperparameter search, train your model with the best combination of hyperparameters. Run the model on the test set and submit the results to the Kaggle competition. To get full marks, your model should outperform the baseline model, which is provided in Kaggle. You **must** show your test accuracy computed by Kaggle in this report.\n",
        "\n",
        "#### **1-3. Model Analysis.** [[4 points]](https://) Conduct a thorough analysis of your model, including:\n",
        "\n",
        "#### **1-3-1. Confusion Matrix:** Split the training set into train/validation sets. The data is organized into eight runs, in order, with each run repeating the same 20 music trials. You should split the data by run. Retrain your model using the best hyperparameter combination. Present the confusion matrix on the validation set.\n",
        "\n",
        "#### **1-3-2. Example Examination:** Examine four validation samples where your model fails to classify into the correct category. Display the true label and the predicted label. Looking at the confusion matrix, how might you explain your results from the perspectives of human brain data and music genre similarity?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vA9cw0emNkjC"
      },
      "source": [
        "---\n",
        "\n",
        "## **A. Data Download**\n",
        "\n",
        "#### For your convenience, we have provided code to download the dataset, which includes true labels, training data (features), training labels, and testing data (features).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBfZLkUrZ9Xx"
      },
      "source": [
        "#### **A-1. Download Features and Labels.**\n",
        "\n",
        "#### Run the following code to download the brain features and labels of the music clips.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tvMqDITgzRW2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gdown\n",
            "  Downloading gdown-5.1.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /home/jonathan/.pyenv/versions/3.12.2/envs/ml-exp/lib/python3.12/site-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /home/jonathan/.pyenv/versions/3.12.2/envs/ml-exp/lib/python3.12/site-packages (from gdown) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /home/jonathan/.pyenv/versions/3.12.2/envs/ml-exp/lib/python3.12/site-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /home/jonathan/.pyenv/versions/3.12.2/envs/ml-exp/lib/python3.12/site-packages (from gdown) (4.66.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /home/jonathan/.pyenv/versions/3.12.2/envs/ml-exp/lib/python3.12/site-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jonathan/.pyenv/versions/3.12.2/envs/ml-exp/lib/python3.12/site-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/jonathan/.pyenv/versions/3.12.2/envs/ml-exp/lib/python3.12/site-packages (from requests[socks]->gdown) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jonathan/.pyenv/versions/3.12.2/envs/ml-exp/lib/python3.12/site-packages (from requests[socks]->gdown) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/jonathan/.pyenv/versions/3.12.2/envs/ml-exp/lib/python3.12/site-packages (from requests[socks]->gdown) (2024.2.2)\n",
            "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown)\n",
            "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading gdown-5.1.0-py3-none-any.whl (17 kB)\n",
            "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: PySocks, gdown\n",
            "Successfully installed PySocks-1.7.1 gdown-5.1.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OjIWRNJzodXk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/jonathan/.pyenv/versions/3.12.2/envs/ml-exp/lib/python3.12/site-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1aFDPryEDcT5wg0k8NhWYpF8lulGmot5J\n",
            "To: /home/jonathan/external/le-wagon-data-science/project/project/train_data.csv\n",
            "100%|██████████████████████████████████████| 89.7M/89.7M [00:25<00:00, 3.45MB/s]\n",
            "/home/jonathan/.pyenv/versions/3.12.2/envs/ml-exp/lib/python3.12/site-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=11kgAdB_hkEcC4npCEWJcAOOmGe3495yY\n",
            "To: /home/jonathan/external/le-wagon-data-science/project/project/train_labels.csv\n",
            "100%|██████████████████████████████████████████| 320/320 [00:00<00:00, 1.37MB/s]\n",
            "/home/jonathan/.pyenv/versions/3.12.2/envs/ml-exp/lib/python3.12/site-packages/gdown/__main__.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1wXq56F6RIUtDzPceZegZAMA-JGW21Gqu\n",
            "To: /home/jonathan/external/le-wagon-data-science/project/project/test_data.csv\n",
            "100%|██████████████████████████████████████| 22.5M/22.5M [00:07<00:00, 3.14MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1aFDPryEDcT5wg0k8NhWYpF8lulGmot5J # train data\n",
        "!gdown --id 11kgAdB_hkEcC4npCEWJcAOOmGe3495yY # train labels\n",
        "!gdown --id 1wXq56F6RIUtDzPceZegZAMA-JGW21Gqu # test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FA1IkzqxNFw7",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_data.shape: (160, 22036)\n",
            "train_labels.shape: (160, 1)\n",
            "test_data.shape: (40, 22036)\n"
          ]
        }
      ],
      "source": [
        "# Data Import Method 1, with pandas\n",
        "import pandas as pd\n",
        "\n",
        "train_data = pd.read_csv(\"train_data.csv\", header=None)\n",
        "train_labels = pd.read_csv(\"train_labels.csv\", header=None)\n",
        "test_data = pd.read_csv(\"test_data.csv\", header=None)\n",
        "\n",
        "print('train_data.shape: {}'.format(train_data.shape))\n",
        "print('train_labels.shape: {}'.format(train_labels.shape))\n",
        "print('test_data.shape: {}'.format(test_data.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Data exploration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "First few rows of the dataset:\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>22026</th>\n",
              "      <th>22027</th>\n",
              "      <th>22028</th>\n",
              "      <th>22029</th>\n",
              "      <th>22030</th>\n",
              "      <th>22031</th>\n",
              "      <th>22032</th>\n",
              "      <th>22033</th>\n",
              "      <th>22034</th>\n",
              "      <th>22035</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.742153</td>\n",
              "      <td>-0.776961</td>\n",
              "      <td>-1.482406</td>\n",
              "      <td>-2.372191</td>\n",
              "      <td>-1.397303</td>\n",
              "      <td>-1.511740</td>\n",
              "      <td>-2.833305</td>\n",
              "      <td>-1.207638</td>\n",
              "      <td>0.748228</td>\n",
              "      <td>-0.925093</td>\n",
              "      <td>...</td>\n",
              "      <td>1.700659</td>\n",
              "      <td>0.193262</td>\n",
              "      <td>-0.903444</td>\n",
              "      <td>-1.221330</td>\n",
              "      <td>-0.044282</td>\n",
              "      <td>0.356661</td>\n",
              "      <td>1.069074</td>\n",
              "      <td>1.587395</td>\n",
              "      <td>0.880437</td>\n",
              "      <td>-0.097743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.706499</td>\n",
              "      <td>-3.121015</td>\n",
              "      <td>1.604055</td>\n",
              "      <td>-2.142794</td>\n",
              "      <td>-4.990133</td>\n",
              "      <td>1.331979</td>\n",
              "      <td>-0.729106</td>\n",
              "      <td>-4.301400</td>\n",
              "      <td>-0.815633</td>\n",
              "      <td>0.976097</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.589694</td>\n",
              "      <td>0.620819</td>\n",
              "      <td>-0.236290</td>\n",
              "      <td>0.209095</td>\n",
              "      <td>1.578962</td>\n",
              "      <td>1.518740</td>\n",
              "      <td>0.758905</td>\n",
              "      <td>-2.542966</td>\n",
              "      <td>-0.663301</td>\n",
              "      <td>1.886257</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 22036 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      0         1         2         3         4         5         6      \\\n",
              "0 -0.742153 -0.776961 -1.482406 -2.372191 -1.397303 -1.511740 -2.833305   \n",
              "1  0.706499 -3.121015  1.604055 -2.142794 -4.990133  1.331979 -0.729106   \n",
              "\n",
              "      7         8         9      ...     22026     22027     22028     22029  \\\n",
              "0 -1.207638  0.748228 -0.925093  ...  1.700659  0.193262 -0.903444 -1.221330   \n",
              "1 -4.301400 -0.815633  0.976097  ... -0.589694  0.620819 -0.236290  0.209095   \n",
              "\n",
              "      22030     22031     22032     22033     22034     22035  \n",
              "0 -0.044282  0.356661  1.069074  1.587395  0.880437 -0.097743  \n",
              "1  1.578962  1.518740  0.758905 -2.542966 -0.663301  1.886257  \n",
              "\n",
              "[2 rows x 22036 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"\\nFirst few rows of the dataset:\\n\")\n",
        "train_data.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Descriptive statistics for numerical columns:\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>22026</th>\n",
              "      <th>22027</th>\n",
              "      <th>22028</th>\n",
              "      <th>22029</th>\n",
              "      <th>22030</th>\n",
              "      <th>22031</th>\n",
              "      <th>22032</th>\n",
              "      <th>22033</th>\n",
              "      <th>22034</th>\n",
              "      <th>22035</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>160.000000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>160.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-0.066006</td>\n",
              "      <td>-0.154871</td>\n",
              "      <td>-0.020606</td>\n",
              "      <td>-0.199492</td>\n",
              "      <td>-0.315309</td>\n",
              "      <td>0.022948</td>\n",
              "      <td>-0.177308</td>\n",
              "      <td>-0.304146</td>\n",
              "      <td>0.022068</td>\n",
              "      <td>-0.005677</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.547745</td>\n",
              "      <td>-0.441539</td>\n",
              "      <td>-0.173822</td>\n",
              "      <td>-0.007579</td>\n",
              "      <td>0.095730</td>\n",
              "      <td>0.064561</td>\n",
              "      <td>0.041727</td>\n",
              "      <td>-0.111381</td>\n",
              "      <td>-0.265452</td>\n",
              "      <td>-0.223489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.500774</td>\n",
              "      <td>1.676715</td>\n",
              "      <td>1.636009</td>\n",
              "      <td>1.599417</td>\n",
              "      <td>1.900022</td>\n",
              "      <td>1.932757</td>\n",
              "      <td>1.751882</td>\n",
              "      <td>1.804820</td>\n",
              "      <td>1.859196</td>\n",
              "      <td>2.062696</td>\n",
              "      <td>...</td>\n",
              "      <td>3.519517</td>\n",
              "      <td>3.312260</td>\n",
              "      <td>2.269050</td>\n",
              "      <td>1.851351</td>\n",
              "      <td>1.967000</td>\n",
              "      <td>1.815714</td>\n",
              "      <td>3.320270</td>\n",
              "      <td>3.169256</td>\n",
              "      <td>3.180904</td>\n",
              "      <td>3.128345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-3.380314</td>\n",
              "      <td>-3.793518</td>\n",
              "      <td>-3.758160</td>\n",
              "      <td>-4.364808</td>\n",
              "      <td>-6.444076</td>\n",
              "      <td>-4.605515</td>\n",
              "      <td>-4.875474</td>\n",
              "      <td>-6.704030</td>\n",
              "      <td>-5.600730</td>\n",
              "      <td>-5.121164</td>\n",
              "      <td>...</td>\n",
              "      <td>-14.137297</td>\n",
              "      <td>-15.444844</td>\n",
              "      <td>-8.063930</td>\n",
              "      <td>-5.977312</td>\n",
              "      <td>-4.995636</td>\n",
              "      <td>-5.088302</td>\n",
              "      <td>-9.083015</td>\n",
              "      <td>-7.866581</td>\n",
              "      <td>-10.144498</td>\n",
              "      <td>-12.688218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-1.277234</td>\n",
              "      <td>-1.220757</td>\n",
              "      <td>-1.182044</td>\n",
              "      <td>-1.293862</td>\n",
              "      <td>-1.431364</td>\n",
              "      <td>-1.223549</td>\n",
              "      <td>-1.218873</td>\n",
              "      <td>-1.487742</td>\n",
              "      <td>-1.207912</td>\n",
              "      <td>-1.404501</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.629624</td>\n",
              "      <td>-2.187987</td>\n",
              "      <td>-1.477697</td>\n",
              "      <td>-1.182528</td>\n",
              "      <td>-1.257316</td>\n",
              "      <td>-1.308150</td>\n",
              "      <td>-1.948154</td>\n",
              "      <td>-2.009556</td>\n",
              "      <td>-2.434278</td>\n",
              "      <td>-2.089949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-0.045241</td>\n",
              "      <td>-0.070804</td>\n",
              "      <td>0.084998</td>\n",
              "      <td>-0.243672</td>\n",
              "      <td>-0.241066</td>\n",
              "      <td>0.111487</td>\n",
              "      <td>-0.343154</td>\n",
              "      <td>-0.059158</td>\n",
              "      <td>0.029654</td>\n",
              "      <td>0.105428</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.407929</td>\n",
              "      <td>-0.326650</td>\n",
              "      <td>-0.228918</td>\n",
              "      <td>-0.097626</td>\n",
              "      <td>0.152068</td>\n",
              "      <td>0.039733</td>\n",
              "      <td>-0.010232</td>\n",
              "      <td>-0.239472</td>\n",
              "      <td>-0.149464</td>\n",
              "      <td>-0.303842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.729169</td>\n",
              "      <td>1.008135</td>\n",
              "      <td>0.915057</td>\n",
              "      <td>0.719409</td>\n",
              "      <td>0.728420</td>\n",
              "      <td>1.247066</td>\n",
              "      <td>0.963594</td>\n",
              "      <td>0.741256</td>\n",
              "      <td>1.391903</td>\n",
              "      <td>1.247318</td>\n",
              "      <td>...</td>\n",
              "      <td>1.635445</td>\n",
              "      <td>1.383985</td>\n",
              "      <td>1.041755</td>\n",
              "      <td>1.189738</td>\n",
              "      <td>1.335793</td>\n",
              "      <td>1.409330</td>\n",
              "      <td>2.201923</td>\n",
              "      <td>1.752236</td>\n",
              "      <td>1.403248</td>\n",
              "      <td>1.449921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5.342589</td>\n",
              "      <td>6.003043</td>\n",
              "      <td>5.417107</td>\n",
              "      <td>4.935417</td>\n",
              "      <td>5.761523</td>\n",
              "      <td>4.705943</td>\n",
              "      <td>5.581067</td>\n",
              "      <td>3.970444</td>\n",
              "      <td>4.880188</td>\n",
              "      <td>4.969017</td>\n",
              "      <td>...</td>\n",
              "      <td>11.662434</td>\n",
              "      <td>9.202734</td>\n",
              "      <td>5.752860</td>\n",
              "      <td>4.299949</td>\n",
              "      <td>4.982888</td>\n",
              "      <td>5.111739</td>\n",
              "      <td>8.265574</td>\n",
              "      <td>10.155688</td>\n",
              "      <td>10.912566</td>\n",
              "      <td>8.827926</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 22036 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0           1           2           3           4           5      \\\n",
              "count  160.000000  160.000000  160.000000  160.000000  160.000000  160.000000   \n",
              "mean    -0.066006   -0.154871   -0.020606   -0.199492   -0.315309    0.022948   \n",
              "std      1.500774    1.676715    1.636009    1.599417    1.900022    1.932757   \n",
              "min     -3.380314   -3.793518   -3.758160   -4.364808   -6.444076   -4.605515   \n",
              "25%     -1.277234   -1.220757   -1.182044   -1.293862   -1.431364   -1.223549   \n",
              "50%     -0.045241   -0.070804    0.084998   -0.243672   -0.241066    0.111487   \n",
              "75%      0.729169    1.008135    0.915057    0.719409    0.728420    1.247066   \n",
              "max      5.342589    6.003043    5.417107    4.935417    5.761523    4.705943   \n",
              "\n",
              "            6           7           8           9      ...       22026  \\\n",
              "count  160.000000  160.000000  160.000000  160.000000  ...  160.000000   \n",
              "mean    -0.177308   -0.304146    0.022068   -0.005677  ...   -0.547745   \n",
              "std      1.751882    1.804820    1.859196    2.062696  ...    3.519517   \n",
              "min     -4.875474   -6.704030   -5.600730   -5.121164  ...  -14.137297   \n",
              "25%     -1.218873   -1.487742   -1.207912   -1.404501  ...   -2.629624   \n",
              "50%     -0.343154   -0.059158    0.029654    0.105428  ...   -0.407929   \n",
              "75%      0.963594    0.741256    1.391903    1.247318  ...    1.635445   \n",
              "max      5.581067    3.970444    4.880188    4.969017  ...   11.662434   \n",
              "\n",
              "            22027       22028       22029       22030       22031       22032  \\\n",
              "count  160.000000  160.000000  160.000000  160.000000  160.000000  160.000000   \n",
              "mean    -0.441539   -0.173822   -0.007579    0.095730    0.064561    0.041727   \n",
              "std      3.312260    2.269050    1.851351    1.967000    1.815714    3.320270   \n",
              "min    -15.444844   -8.063930   -5.977312   -4.995636   -5.088302   -9.083015   \n",
              "25%     -2.187987   -1.477697   -1.182528   -1.257316   -1.308150   -1.948154   \n",
              "50%     -0.326650   -0.228918   -0.097626    0.152068    0.039733   -0.010232   \n",
              "75%      1.383985    1.041755    1.189738    1.335793    1.409330    2.201923   \n",
              "max      9.202734    5.752860    4.299949    4.982888    5.111739    8.265574   \n",
              "\n",
              "            22033       22034       22035  \n",
              "count  160.000000  160.000000  160.000000  \n",
              "mean    -0.111381   -0.265452   -0.223489  \n",
              "std      3.169256    3.180904    3.128345  \n",
              "min     -7.866581  -10.144498  -12.688218  \n",
              "25%     -2.009556   -2.434278   -2.089949  \n",
              "50%     -0.239472   -0.149464   -0.303842  \n",
              "75%      1.752236    1.403248    1.449921  \n",
              "max     10.155688   10.912566    8.827926  \n",
              "\n",
              "[8 rows x 22036 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"\\nDescriptive statistics for numerical columns:\\n\")\n",
        "train_data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Information about the dataset:\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 160 entries, 0 to 159\n",
            "Columns: 22036 entries, 0 to 22035\n",
            "dtypes: float64(22036)\n",
            "memory usage: 26.9 MB\n",
            "None\n",
            "\n",
            "Shape of the dataset (rows, columns):\n",
            "\n",
            "(160, 22036)\n",
            "\n",
            "Data types of each column:\n",
            "\n",
            "0        float64\n",
            "1        float64\n",
            "2        float64\n",
            "3        float64\n",
            "4        float64\n",
            "          ...   \n",
            "22031    float64\n",
            "22032    float64\n",
            "22033    float64\n",
            "22034    float64\n",
            "22035    float64\n",
            "Length: 22036, dtype: object\n",
            "\n",
            "Number of missing values in each column:\n",
            "\n",
            "0        0\n",
            "1        0\n",
            "2        0\n",
            "3        0\n",
            "4        0\n",
            "        ..\n",
            "22031    0\n",
            "22032    0\n",
            "22033    0\n",
            "22034    0\n",
            "22035    0\n",
            "Length: 22036, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nInformation about the dataset:\\n\")\n",
        "print(train_data.info())\n",
        "\n",
        "print(\"\\nShape of the dataset (rows, columns):\\n\")\n",
        "print(train_data.shape)\n",
        "\n",
        "print(\"\\nData types of each column:\\n\")\n",
        "print(train_data.dtypes)\n",
        "\n",
        "# print(df['categorical_column'].value_counts())\n",
        "\n",
        "print(\"\\nNumber of missing values in each column:\\n\")\n",
        "print(train_data.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 1: Split the data into training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_data, train_labels, test_size=0.3, random_state=42) # 70% to train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 2: Normalize the features using StandardScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_normalized = scaler.fit_transform(X_train)\n",
        "X_test_normalized = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 3: One-hot encode the target variable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "y_train_encoded = encoder.fit_transform(y_train.values.reshape(-1, 1))\n",
        "y_test_encoded = encoder.transform(y_test.values.reshape(-1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [1., 0., 0., 0., 0.]])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train_encoded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 4: Create a simple sequential model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.42885375494071154\n",
            "{'classifier__estimator__n_neighbors': 1, 'classifier__estimator__p': 4, 'pca__n_components': 3}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "pca = PCA()\n",
        "model = KNeighborsClassifier()\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('features', StandardScaler(), X_train.columns),\n",
        "    ])\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('pca', pca),\n",
        "    ('classifier', MultiOutputClassifier(model))\n",
        "])\n",
        "\n",
        "# Hyperparameter Grid\n",
        "grid = {\n",
        "    'pca__n_components': [1, 2, 3, 4, 5],\n",
        "    'classifier__estimator__n_neighbors': [1, 2, 3, 4, 5, 6],\n",
        "    'classifier__estimator__p': [4, 5, 6, 7, 8]\n",
        "}\n",
        "\n",
        "# Instantiate Grid Search\n",
        "search = GridSearchCV(\n",
        "    pipeline,\n",
        "    grid, \n",
        "    cv = 5,\n",
        "    n_jobs=-1 # parallelize computation\n",
        ") \n",
        "\n",
        "# Fit data to Grid Search\n",
        "search.fit(X_train, y_train_encoded)\n",
        "\n",
        "print(search.best_score_)\n",
        "print(search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.20833333333333334"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "search.best_estimator_.score(X_test_normalized, y_test_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Instantiate model\n",
        "model = KNeighborsClassifier()\n",
        "\n",
        "# Wrap the classifier with MultiOutputClassifier\n",
        "multioutput_classifier = MultiOutputClassifier(model)\n",
        "\n",
        "# Hyperparameter Grid\n",
        "grid = {\n",
        "    'estimator__n_neighbors': [1, 2, 3, 4, 5, 6, 7, 9],\n",
        "    'estimator__p': [1, 2, 3, 4, 5]\n",
        "}\n",
        "\n",
        "# Instantiate Grid Search\n",
        "search = GridSearchCV(\n",
        "    multioutput_classifier,\n",
        "    grid, \n",
        "    cv = 5,\n",
        "    n_jobs=-1 # parallelize computation\n",
        ") \n",
        "\n",
        "# Fit data to Grid Search\n",
        "search.fit(X_train_normalized, y_train_encoded);\n",
        "\n",
        "print(search.best_score_)\n",
        "print(search.best_params_)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
